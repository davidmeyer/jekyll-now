\begin{thebibliography}{10}

\bibitem{2018arXiv180310232I}
R.~{Istrate}, A.~{Cristiano Innocenza Malossi}, C.~{Bekas}, and
  D.~{Nikolopoulos}, ``{Incremental Training of Deep Convolutional Neural
  Networks},'' {\em ArXiv e-prints}, Mar. 2018.

\bibitem{2017arXiv170803074V}
A.~{Valadarsky}, M.~{Schapira}, D.~{Shahaf}, and A.~{Tamar}, ``{A Machine
  Learning Approach to Routing},'' {\em ArXiv e-prints}, Aug. 2017.

\bibitem{Ahuja:1990:FAS:77600.77615}
R.~K. Ahuja, K.~Mehlhorn, J.~Orlin, and R.~E. Tarjan, ``Faster algorithms for
  the shortest path problem,'' {\em J. ACM}, vol.~37, pp.~213--223, Apr. 1990.

\bibitem{2018arXiv180209474S}
O.~{San}, R.~{Maulik}, and M.~{Ahmed}, ``{An artificial neural network
  framework for reduced order modeling of transient flows},'' {\em ArXiv
  e-prints}, Feb. 2018.

\bibitem{PhysRevLett.59.2229}
F.~J. Pineda, ``Generalization of back-propagation to recurrent neural
  networks,'' {\em Phys. Rev. Lett.}, vol.~59, pp.~2229--2232, Nov 1987.

\bibitem{DBLP:conf/sigcomm/GeyerC18}
F.~Geyer and G.~Carle, ``Learning and generating distributed routing protocols
  using graph-based deep learning,'' in {\em Proceedings of the 2018 Workshop
  on Big Data Analytics and Machine Learning for Data Communication Networks,
  Big-DAMA@SIGCOMM 2018, Budapest, Hungary, August 20, 2018}, pp.~40--45, 2018.

\bibitem{Scarselli:2009:GNN:1657477.1657482}
F.~Scarselli, M.~Gori, A.~C. Tsoi, M.~Hagenbuchner, and G.~Monfardini, ``The
  graph neural network model,'' {\em Trans. Neur. Netw.}, vol.~20, pp.~61--80,
  Jan. 2009.

\bibitem{2017arXiv170105923D}
R.~{Dey} and F.~M. {Salem}, ``{Gate-Variants of Gated Recurrent Unit (GRU)
  Neural Networks},'' {\em ArXiv e-prints}, Jan. 2017.

\bibitem{Srivastava:2014:DSW:2627435.2670313}
N.~Srivastava, G.~Hinton, A.~Krizhevsky, I.~Sutskever, and R.~Salakhutdinov,
  ``Dropout: A simple way to prevent neural networks from overfitting,'' {\em
  J. Mach. Learn. Res.}, vol.~15, pp.~1929--1958, Jan. 2014.

\bibitem{Andradottir:1993:VRT:174153.174154}
S.~Andrad\'{o}ttir, D.~P. Heyman, and T.~J. Ott, ``Variance reduction through
  smoothing and control variates for markov chain simulations,'' {\em ACM
  Trans. Model. Comput. Simul.}, vol.~3, pp.~167--189, July 1993.

\bibitem{2016arXiv161101142G}
W.~{Genders} and S.~{Razavi}, ``{Using a Deep Reinforcement Learning Agent for
  Traffic Signal Control},'' {\em ArXiv e-prints}, Nov. 2016.

\bibitem{Walraven:2016:TFO:2937770.2937891}
E.~Walraven, M.~T. Spaan, and B.~Bakker, ``Traffic flow optimization,'' {\em
  Eng. Appl. Artif. Intell.}, vol.~52, pp.~203--212, June 2016.

\bibitem{2018arXiv181001257N}
O.~{Nachum}, S.~{Gu}, H.~{Lee}, and S.~{Levine}, ``{Near-Optimal Representation
  Learning for Hierarchical Reinforcement Learning},'' {\em ArXiv e-prints},
  Oct. 2018.

\bibitem{2017arXiv170908339W}
M.~{Wang}, Y.~{Cui}, X.~{Wang}, S.~{Xiao}, and J.~{Jiang}, ``{Machine Learning
  for Networking: Workflow, Advances and Opportunities},'' {\em ArXiv
  e-prints}, Sept. 2017.

\bibitem{Stampa:2017aa}
G.~Stampa, M.~Arias, D.~Sanchez-Charles, V.~Muntes-Mulero, and A.~Cabellos, ``A
  deep-reinforcement learning approach for software-defined networking routing
  optimization,'' 09 2017.

\bibitem{Tao:2001aa}
N.~Tao, N.~Tao, J.~Baxter, and L.~Weaver, ``A multi-agent, policy-gradient
  approach to network routing,'' {\em IN: PROC. OF THE 18TH INT. CONF. ON
  MACHINE LEARNING}, pp.~553--560, 2001.

\bibitem{Lillicrap:2015aa}
T.~P. Lillicrap, J.~J. Hunt, A.~Pritzel, N.~Heess, T.~Erez, Y.~Tassa,
  D.~Silver, and D.~Wierstra, ``Continuous control with deep reinforcement
  learning,'' 09 2015.

\bibitem{NIPS2015_5775}
K.~Sohn, H.~Lee, and X.~Yan, ``Learning structured output representation using
  deep conditional generative models,'' in {\em Advances in Neural Information
  Processing Systems 28} (C.~Cortes, N.~D. Lawrence, D.~D. Lee, M.~Sugiyama,
  and R.~Garnett, eds.), pp.~3483--3491, Curran Associates, Inc., 2015.

\bibitem{Peters:2011:ICG:3020548.3020617}
J.~Peters, J.~M. Mooij, D.~Janzing, and B.~Sch\"{o}lkopf, ``Identifiability of
  causal graphs using functional models,'' in {\em Proceedings of the
  Twenty-Seventh Conference on Uncertainty in Artificial Intelligence}, UAI'11,
  (Arlington, Virginia, United States), pp.~589--598, AUAI Press, 2011.

\bibitem{2018arXiv180210031T}
G.~{Tucker}, S.~{Bhupatiraju}, S.~{Gu}, R.~E. {Turner}, Z.~{Ghahramani}, and
  S.~{Levine}, ``{The Mirage of Action-Dependent Baselines in Reinforcement
  Learning},'' {\em ArXiv e-prints}, Feb. 2018.

\bibitem{2015arXiv150602438S}
J.~{Schulman}, P.~{Moritz}, S.~{Levine}, M.~{Jordan}, and P.~{Abbeel},
  ``{High-Dimensional Continuous Control Using Generalized Advantage
  Estimation},'' {\em ArXiv e-prints}, June 2015.

\bibitem{2018arXiv180307246W}
C.~{Wu}, A.~{Rajeswaran}, Y.~{Duan}, V.~{Kumar}, A.~M. {Bayen}, S.~{Kakade},
  I.~{Mordatch}, and P.~{Abbeel}, ``{Variance Reduction for Policy Gradient
  with Action-Dependent Factorized Baselines},'' {\em ArXiv e-prints}, Mar.
  2018.

\bibitem{2016arXiv161102247G}
S.~{Gu}, T.~{Lillicrap}, Z.~{Ghahramani}, R.~E. {Turner}, and S.~{Levine},
  ``{Q-Prop: Sample-Efficient Policy Gradient with An Off-Policy Critic},''
  {\em ArXiv e-prints}, Nov. 2016.

\bibitem{oALE68a}
V.~M. Aleksandrov, V.~I. Sysoyev, and V.~V. Shemeneva, ``Stochastic
  optimization,'' {\em Engineering Cybernetics}, vol.~5, pp.~11--16, 1968.

\bibitem{Baxter:2001:IPE:1622845.1622855}
J.~Baxter and P.~L. Bartlett, ``Infinite-horizon policy-gradient estimation,''
  {\em J. Artif. Int. Res.}, vol.~15, pp.~319--350, Nov. 2001.

\bibitem{2016arXiv161001945P}
D.~{Pfau} and O.~{Vinyals}, ``{Connecting Generative Adversarial Networks and
  Actor-Critic Methods},'' {\em ArXiv e-prints}, Oct. 2016.

\bibitem{2016arXiv160201783M}
V.~{Mnih}, A.~{Puigdom{\`e}nech Badia}, M.~{Mirza}, A.~{Graves}, T.~P.
  {Lillicrap}, T.~{Harley}, D.~{Silver}, and K.~{Kavukcuoglu}, ``{Asynchronous
  Methods for Deep Reinforcement Learning},'' {\em ArXiv e-prints}, Feb. 2016.

\bibitem{2018arXiv180302811S}
A.~{Stooke} and P.~{Abbeel}, ``{Accelerated Methods for Deep Reinforcement
  Learning},'' {\em ArXiv e-prints}, Mar. 2018.

\bibitem{NIPS1999_1786}
V.~R. Konda and J.~N. Tsitsiklis, ``Actor-critic algorithms,'' in {\em Advances
  in Neural Information Processing Systems 12} (S.~A. Solla, T.~K. Leen, and
  K.~M\"{u}ller, eds.), pp.~1008--1014, MIT Press, 2000.

\bibitem{Greensmith:2004:VRT:1005332.1044710}
E.~Greensmith, P.~L. Bartlett, and J.~Baxter, ``Variance reduction techniques
  for gradient estimates in reinforcement learning,'' {\em J. Mach. Learn.
  Res.}, vol.~5, pp.~1471--1530, Dec. 2004.

\bibitem{2017arXiv170706347S}
J.~{Schulman}, F.~{Wolski}, P.~{Dhariwal}, A.~{Radford}, and O.~{Klimov},
  ``{Proximal Policy Optimization Algorithms},'' {\em ArXiv e-prints}, July
  2017.

\bibitem{Williams1992}
R.~J. Williams, ``{Simple statistical gradient-following algorithms for
  connectionist reinforcement learning},'' {\em Machine Learning}, vol.~8,
  no.~3-4, pp.~229--256, 1992.

\bibitem{Peters:2006fk}
J.~Peters and S.~Schaal, ``{Policy gradient methods for robotics},'' in {\em
  {Proceedings of the IEEE/RSJ International Conference on Intelligent Robots
  and Systems (IROS)}}, (Beijing, China), 2006.

\bibitem{Silver:2014:DPG:3044805.3044850}
D.~Silver, G.~Lever, N.~Heess, T.~Degris, D.~Wierstra, and M.~Riedmiller,
  ``Deterministic policy gradient algorithms,'' in {\em Proceedings of the 31st
  International Conference on International Conference on Machine Learning -
  Volume 32}, ICML'14, pp.~I--387--I--395, JMLR.org, 2014.

\bibitem{Kakade+Langford:2002}
S.~Kakade and J.~Langford, ``Approximately optimal approximate reinforcement
  learning,'' in {\em Proceedings of the Nineteenth International Conference on
  Machine Learning (ICML 2002)} (C.~Sammut and A.~Hoffman, eds.), (San
  Francisco, CA, USA), pp.~267--274, Morgan Kauffman, 2002.

\bibitem{DBLP:journals/corr/SchulmanLMJA15}
J.~Schulman, S.~Levine, P.~Moritz, M.~I. Jordan, and P.~Abbeel, ``Trust region
  policy optimization,'' {\em CoRR}, vol.~abs/1502.05477, 2015.

\bibitem{Schulman:2015ab}
J.~Schulman, S.~Levine, P.~Moritz, M.~I. Jordan, and P.~Abbeel, ``Trust region
  policy optimization,'' 02 2015.

\bibitem{Schulman:2015aa}
J.~Schulman, N.~Heess, T.~Weber, and P.~Abbeel, ``Gradient estimation using
  stochastic computation graphs,'' 06 2015.

\bibitem{Goodfellow:2017aa}
I.~Goodfellow, ``{NIPS} 2016 tutorial: Generative adversarial networks,'' 01
  2017.

\bibitem{Vaswani:2017aa}
A.~Vaswani, N.~Shazeer, N.~Parmar, J.~Uszkoreit, L.~Jones, A.~N. Gomez,
  L.~Kaiser, and I.~Polosukhin, ``Attention is all you need,'' 06 2017.

\bibitem{Bahdanau:2014aa}
D.~Bahdanau, K.~Cho, and Y.~Bengio, ``Neural machine translation by jointly
  learning to align and translate,'' 09 2014.

\bibitem{GRAVES2013}
A.~Graves, ``Generating sequences with recurrent neural networks,'' 08 2013.

\bibitem{2018arXiv180408403S}
G.~{Shen}, L.~{Li}, Y.~{Zhang}, W.~{Chen}, S.~K. {Bose}, and M.~{Zukerman},
  ``{Machine Learning-Assisted Least Loaded Routing to Improve Performance of
  Circuit-Switched Networks},'' {\em ArXiv e-prints}, Apr. 2018.

\bibitem{2017arXiv170907080S}
G.~{Stampa}, M.~{Arias}, D.~{Sanchez-Charles}, V.~{Muntes-Mulero}, and
  A.~{Cabellos}, ``{A Deep-Reinforcement Learning Approach for Software-Defined
  Networking Routing Optimization},'' {\em ArXiv e-prints}, Sept. 2017.

\bibitem{2018arXiv180204240N}
M.~{Nazari}, A.~{Oroojlooy}, L.~V. {Snyder}, and M.~{Tak{\'a}{\v c}},
  ``{Reinforcement Learning for Solving the Vehicle Routing Problem},'' {\em
  ArXiv e-prints}, Feb. 2018.

\bibitem{7925316}
M.~Kavalerov, Y.~Likhacheva, and Y.~Shilova, ``A reinforcement learning
  approach to network routing based on adaptive learning rates and route
  memory,'' in {\em SoutheastCon 2017}, pp.~1--6, March 2017.

\bibitem{DBLP:journals/cm/AyoubiLSSBSR18}
S.~Ayoubi, N.~Limam, M.~A. Salahuddin, N.~Shahriar, R.~Boutaba, F.~E. Solano,
  and O.~M.~C. Rendon, ``Machine learning for cognitive network management,''
  {\em {IEEE} Communications Magazine}, vol.~56, no.~1, pp.~158--165, 2018.

\bibitem{DBLP:journals/jisa/BoutabaSLASSR18}
R.~Boutaba, M.~A. Salahuddin, N.~Limam, S.~Ayoubi, N.~Shahriar, F.~E. Solano,
  and O.~M.~C. Rendon, ``A comprehensive survey on machine learning for
  networking: evolution, applications and research opportunities,'' {\em J.
  Internet Services and Applications}, vol.~9, no.~1, pp.~16:1--16:99, 2018.

\bibitem{2018arXiv180807647P}
M.~{Polese}, R.~{Jana}, V.~{Kounev}, K.~{Zhang}, S.~{Deb}, and M.~{Zorzi},
  ``{Machine Learning at the Edge: A Data-Driven Architecture with Applications
  to 5G Cellular Networks},'' {\em ArXiv e-prints}, Aug. 2018.

\bibitem{2018arXiv180307976M}
F.~{Musumeci}, C.~{Rottondi}, A.~{Nag}, I.~{Macaluso}, D.~{Zibar},
  M.~{Ruffini}, and M.~{Tornatore}, ``{A Survey on Application of Machine
  Learning Techniques in Optical Networks},'' {\em ArXiv e-prints}, Mar. 2018.

\bibitem{2017arXiv171203890S}
C.~{Streiffer}, H.~{Chen}, T.~{Benson}, and A.~{Kadav}, ``{DeepConfig:
  Automating Data Center Network Topologies Management with Machine
  Learning},'' {\em ArXiv e-prints}, Dec. 2017.

\bibitem{Sutton:1998:IRL:551283}
R.~S. Sutton and A.~G. Barto, {\em Introduction to Reinforcement Learning}.
\newblock Cambridge, MA, USA: MIT Press, 1st~ed., 1998.

\end{thebibliography}
